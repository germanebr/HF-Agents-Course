{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will showcase the capabilities of the Hugging Face **smolagents** library, which provides a lightweitght framework for creating AI agents.\n",
    "\n",
    "The following code samples will exemplify how to use this package to build agents capable of searching for data, executing code, and interacting with web pages. Finally, we'll review how to combine multiple agents to create more powerful systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowing *smolagents*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package *smolagents* is a framework for building AI agents, providing LLMs with the agency to interact with the real world, like searching or generating images.\n",
    "\n",
    "These are some of the main advantages of using this package for building your AI Agents:\n",
    "\n",
    "* **Simplicity.** Has minimal code complexity and abstractions to make the framework easy to understand and use\n",
    "* **Flexible LLM Support.** The package is capable of working with any LLM through integration with Hugging Face tools and external APIs\n",
    "* **Code-First Approach.** It has first-class support for Code Agents that write their actions directly in code, removing the need for parsing and simplifying tool calling\n",
    "* **HF Hub Integrations.** It also counts with seamless integration with the Hugging Face Hub, allowing the use of Gradio Sapces as tools\n",
    "\n",
    "Another difference with other frameworks is that *smolagents* focuses on tool calls in code instead of writing actions in JSON format. This skips the need to parse the JSON data in order to build code that calls the tools, and executing it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to use this package under the following situations:\n",
    "\n",
    "* You need a **lightweight and minimal solution**\n",
    "* You want to **experiment quickly** without complex configurations\n",
    "* Your **application logic is straightforward**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package works with **multi-step agents**, where each perform the following:\n",
    "\n",
    "* One thought\n",
    "* One tool call and execution\n",
    "\n",
    "The primary agent of the package is the **CodeAgent**, although it also supports **ToolCallingAgent**, which writes tool calls in JSON, like other frameworks.\n",
    "\n",
    "It is important to mention that the package defines its tools with the *@tool* decorator, or using the *Tool* class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model integration of the package supports flexible connection with multiple LLM models that meet certain criteria. These are some of the predefined classes that allow model connection:\n",
    "\n",
    "* **TransformersModel.** Implements local transformers pipelines for seamless integration\n",
    "* **HfApiModel.** Supports serverless inference calls through the *Hugging Face's infrastructure*, or through *third-party inference providers*\n",
    "* **LiteLLMModel.** Leverages *LiteLLM* for lightweight model interactions\n",
    "* **OpenAIServerModel.** Connects to any service that offers an OpenAI API interface\n",
    "* **AzureOpenAIServerModel.** Supports integration with any Azure OpenAI deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agents that Use Code\n",
    "\n",
    "As mentioned before, the core agent type of *smolagents* is the **Code Agent** that generates Python tool calls to perform actions. This approach reduces the number of required actions, simplifies complex operations, and enables reuse of existing code functions.\n",
    "\n",
    "The general approach that most of the frameworks follow is to use a JSON format to specify tool names and arguments as strings, which then the system **must parse to determine which tool to execute**. However, there are studies that suggest that **tool-calling LLMs work more effectively with code directly**, being some of the core advantages the following:\n",
    "\n",
    "* **Composability.** Easily combine and reuse actions\n",
    "* **Object Management.** Work directly with complex structures like images\n",
    "* **Generality.** Express any computationally possible task\n",
    "* **Natural for LLMs.** High-quality code is already present in LLM training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *CodeAgent* performs actions through a cycle of steps, with existing variables and knowledge being incorporated into the agent's context, which is kept in an execution log.\n",
    "\n",
    "1. The system prompt is stored in a **SystemPromptStep**, and the user query is logged in a **TaskStep**\n",
    "2. The following loop is executed:\n",
    "    2.1 Method **agent.write_memory_to_message() writes the agent's logs into a list of LLM-readable chat messages\n",
    "    2.2 These messages are sent to a **Model**, which generates a completion\n",
    "    2.3 The completion is parsed to extract the action, which should be a code snippet\n",
    "    2.4 The action is executed\n",
    "    2.5 The results are logged into memory in an **ActionStep**\n",
    "\n",
    "At the end of each step, if the agent includes any function calls in **agent.step_callback**, they are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the smolagents package\n",
    "# pip install smolagents\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from huggingface_hub import login\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the HF Serverless Inference API\n",
    "with open(\"../hf_token.txt\", \"r\") as f:\n",
    "    hf_token = f.readline()\n",
    "\n",
    "login(token = hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start creating an agent capable of searching the web using DuckDuckGo. We'll use the default model *Qwen/Qwen2.5-Coder-32B-Instruct*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools = [DuckDuckGoSearchTool()],\n",
    "                  model = HfApiModel())\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's mansion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be using the *@tool* decorator to define a custom funciton that acts as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def suggest_menu(occasion:str) -> str:\n",
    "    \"\"\"Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion: the type of occasion for the party.\"\"\"\n",
    "    \n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools = [suggest_menu],\n",
    "                  model = HfApiModel())\n",
    "\n",
    "agent.run(\"Prepare a formal menu for the party.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*smolagents* specializes in agents that write and execute Python code snippets, offering sandboxed execution for security.\n",
    "\n",
    "Code execution has strict security measures: imports outside a predefined safe list are blocked by default. However, you can authorize additional imports by passing them as strings in *additional_authorized_imports*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools = [DuckDuckGoSearchTool(), suggest_menu],\n",
    "                  model = HfApiModel(),\n",
    "                  additional_authorized_imports = [\"datetime\"])\n",
    "\n",
    "agent.run(\"\"\"Alfred needs to prepare for the party. Here are the tasks:\n",
    "          1. Prepare the drinks - 30 minutes\n",
    "          2. Decorate the mansion - 60 minutes\n",
    "          3. Set up the menu - 45 minutes\n",
    "          4. Prepare the music and playlist - 45 minutes\n",
    "          \n",
    "          If we start right now, at what time will the party be ready?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing the code into Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing the code to the Hub\n",
    "hf_username = \"germanebr\"\n",
    "agent.push_to_hub(f'{hf_username}/AlfredAgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an agent from a HF Hub repo\n",
    "alfred_agent = agent.from_hub(f\"{hf_username}/AlfredAgent\")\n",
    "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. the party idea is a 'villain masquerade' theme.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Alfred Agent\n",
    "\n",
    "The following code lists a more complete agent prepared for performing multiple tasks apart from the ones mentioned above. Most of the unseen modules will be discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, FinalAnswerTool, HfApiModel, Tool, tool, VisitWebpageTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def suggest_menu(occasion:str) -> str:\n",
    "    \"\"\"Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion: The type of occasion for the party.\"\"\"\n",
    "    \n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu from the butler.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def catering_serviec_tool(query:str) -> str:\n",
    "    \"\"\"This tool returns the highest-rated catering service in Gotham City.\n",
    "    Args:\n",
    "        query: A search term for finding catering services.\"\"\"\n",
    "    \n",
    "    # List of catering services and their ratings\n",
    "    services = {\"Gotham Catering Co.\": 4.9,\n",
    "                \"Wayne Manor Catering\": 4.8,\n",
    "                \"Gotham City Events\": 4.7}\n",
    "    \n",
    "    # Find the highest rated catering service (simulating search query filtering)\n",
    "    best_service = max(services,\n",
    "                       key = services.get)\n",
    "    return best_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperherPartyThemeTool(Tool):\n",
    "    name = \"superhero_party_theme_generator\"\n",
    "    \n",
    "    description = \"\"\"This tool suggests creative superhero-themed party ideas based on a category.\n",
    "    It returns a unique party theme idea.\"\"\"\n",
    "\n",
    "    inputs = {\"category\": {\"type\": \"string\",\n",
    "                           \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\"}}\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, category:str):\n",
    "        themes = {\"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
    "                  \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
    "                  \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"}\n",
    "        \n",
    "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools = [DuckDuckGoSearchTool(),\n",
    "                           VisitWebpageTool(),\n",
    "                           suggest_menu,\n",
    "                           catering_serviec_tool,\n",
    "                           SuperheroPartyThemeTool()],\n",
    "                  model = HfApiModel(),\n",
    "                  max_steps = 10,\n",
    "                  verbosity_level = 2)\n",
    "\n",
    "agent.run(\"Give me best playlist for a party at the Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the agent with OpenTelemetry and Langfuse\n",
    "\n",
    "*smolagents* is capable to use the **OpenTelemetry** standard for instrumenting agent runs, allowing seamless inspection and logging. Apart from that, by using **Langfuse** and the **SmolagentsInstrumentor**, we can track and analyze the agent's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dependencies\n",
    "# pip install opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../langfuse_token.json\", \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = keys[\"public_key\"]\n",
    "LANGFUSE_SECRET_KEY = keys[\"secret_key\"]\n",
    "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "\n",
    "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "\n",
    "SmolagentsInstrumentor().instrument(tracer_provider=trace_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools=[], model=HfApiModel())\n",
    "alfred_agent = agent.from_hub('sergiopaniego/AlfredAgent', trust_remote_code=True)\n",
    "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")# Tool Calling Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling Agents\n",
    "\n",
    "Tool Calling Agents follow the same multi-step workflow as Code Agents; the only difference is that Tool Calling Agents **generate JSON objects that specify tool anmes and arguments** instead of running code directly. The system then parses the JSON instructions to execute the appropriate tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with the Code Agent, we can give a tool to the Tool Calling Agent using the same structure, but it will generate now a json output instead of parsed code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ToolCallingAgent(tools = [DuckDuckGoSearchTool()],\n",
    "                         model = HfApiModel())\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's Mansion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "As mentioned before, the tools used by the agents to perform actions are treated as **functions that an LLM can call within the agent system**. Its syntax is usually conformed by the following elements:\n",
    "\n",
    "* **Name.** What the tool is called\n",
    "* **Tool description.** What the tool does\n",
    "* **Input types and descriptions.** What arguments the tool accepts\n",
    "* **Output type.** What the tool returns\n",
    "\n",
    "In the case of the *smolagents* framework, tools can be defined in two ways: with the **@tool decorator** or **creating a Tool subclass**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The @tool decorator\n",
    "\n",
    "This is the recommended approach when working with simple tools. The tool definition needs to cover the following:\n",
    "\n",
    "* A **clear and descriptive function name** that allows the LLM understand its purpose\n",
    "* A list of **hints for both inputs and outputs** to ensure proper usage\n",
    "* A **detailed description that includes the tool's Args**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def catering_service_tool(query:str) -> str:\n",
    "    \"\"\"This tool returns the highest-rated catering service in Gotham City.\n",
    "    Args:\n",
    "        query: a search term for finding catering services\"\"\"\n",
    "    \n",
    "    services = {\"Gotham Catering Co.\": 4.9,\n",
    "                \"Wayne Manor Catering\": 4.8,\n",
    "                \"Gotham City Events\": 4.7}\n",
    "    \n",
    "    best_service = max(services,\n",
    "                       key = services.get)\n",
    "    return best_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools = [catering_service_tool],\n",
    "                  model = HfApiModel())\n",
    "agent.run(\"Can you give me the name of the highest-rated catering service in Gotham City?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tool Subclass\n",
    "\n",
    "In the case where the tool is more complex, it is better to create a class instead of a single function. The Tool class will wrap the function with metadata that helps the LLM understand how to use it effectively.\n",
    "\n",
    "The Tool subclass needs to cover the following parameters:\n",
    "\n",
    "* **name**: The tool's name\n",
    "* **description**: A description used to populate the agent's system prompt\n",
    "* **inputs**: A dictionary with keys *type* and *decsription* for every managed input\n",
    "* **output_type**: Specifies hte expected output type\n",
    "* **forward**: The method containing the inference logic to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool, CodeAgent, HfApiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperheroPartyThemeTool(Tool):\n",
    "    name = \"superhero_party_theme_generator\"\n",
    "    description = \"\"\"This tool suggests creative superhero-themed party ideas based on a category.\n",
    "    It returns a unique party theme idea.\"\"\"\n",
    "\n",
    "    inputs = {\"category\": {\"type\": \"string\",\n",
    "                           \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\"}}\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, category:str):\n",
    "        themes = {\"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
    "                  \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
    "                  \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"}\n",
    "        \n",
    "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_theme_tool = SuperheroPartyThemeTool()\n",
    "agent = CodeAgent(tools = [party_theme_tool],\n",
    "                  model = HfApiModel())\n",
    "\n",
    "agent.run(\"What would be a good superhero party idea for a 'villain masquerade' theme?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Toolbox\n",
    "\n",
    "The *smolagents* framework comes with some pre-built tools that can be injected directly into any agent:\n",
    "\n",
    "* **PythonInterpreterTool**\n",
    "* **FinalAnswerTool**\n",
    "* **UserInputTool**\n",
    "* **DuckDuckGoSearchTool**\n",
    "* **GoogleSearchTool**\n",
    "* **VisitWebpageTool**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing and Importing Tools\n",
    "\n",
    "Another great feature from the framework is that it allows to **share custom tools on Hugging Face Hub and import them as well**, even connecting with **HF Spaces** and **LangChain tools**.\n",
    "\n",
    "This is a sample on how to share a custom tool into the HF Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_username = \"germanebr\"\n",
    "\n",
    "with open(\"../hf_token.txt\", \"r\") as f:\n",
    "    hf_token = f.readline()\n",
    "\n",
    "party_theme_tool.push_to_hub(\"{hf_username}/party_theme_tool\",\n",
    "                             token = hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the sample to import a tool from HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import load_tool, CodeAgent, HfApiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generation_tool = load_tool(\"m-ric/text-to-image\",\n",
    "                                  trust_remote_code = True)\n",
    "\n",
    "agent = CodeAgent(tools = [image_generation_tool],\n",
    "                  model = HfApiModel())\n",
    "agent.run(\"Generate an image of a luxurious superhero-themed party at Wayne Manor with made-up superheros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a Hugging Face Space as a Tool\n",
    "\n",
    "You can also import a HF Space as a tool using *Tool.from_space()*. This opens up possibilities for integrating with thousands of spaces from the community for tasks from image generation to data analysis.\n",
    "\n",
    "The tool will connect with the spaces Gradio backend using the *gradio_client*, so make sure to install it via pip if you don’t have it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generation_tool = Tool.from_space(\"black-forest-labs/FLUX.1-schnell\",\n",
    "                                        name = \"image_generator\",\n",
    "                                        description = \"Generate an image from a prompt\")\n",
    "\n",
    "model = HfApiModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "agent = CodeAgent(tools = [image_generation_tool],\n",
    "                  model = model)\n",
    "\n",
    "agent.run(\"Improve this prompt, then generate an image of it.\",\n",
    "          additional_args = {'user_prompt': 'A grand superhero-themed party at Wayne Manor, with Alfred overseeing a luxurious gala'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a LangChain Tool\n",
    "\n",
    "It is also possible to reuse LangChain tools in the *smolagents* workflow using the *Tool.from_langchain()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from smolagents import CodeAgent, HfApiModel, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n",
    "\n",
    "agent = CodeAgent(tools = [search_tool],\n",
    "                  model = model)\n",
    "\n",
    "agent.run(\"Search for luxury entertainment ideas for a superhero-themed event, such as live performances and interactive experiences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Agents\n",
    "\n",
    "Retrieval Augmented Generation (RAG) systems combine the capabilities of data retrieval and generation models to provide context-aware responses. Agentic RAG (Retrieval-Augmented Generation) extends traditional RAG systems by **combining autonomous agents with dynamic knowledge retrieval**.\n",
    "\n",
    "While traditional RAG systems use an LLM to answer queries based on retrieved data, agentic RAG **enables intelligent control of both retrieval and generation processes**, improving efficiency and accuracy.\n",
    "\n",
    "Traditional RAG systems face key limitations, such as **relying on a single retrieval step** and focusing on direct semantic similarity with the user’s query, which may overlook relevant information.\n",
    "\n",
    "Agentic RAG addresses these issues by allowing the agent to autonomously formulate search queries, critique retrieved results, and conduct multiple retrieval steps for a more tailored and comprehensive output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Retrieval with DuckDuckGo\n",
    "\n",
    "This sample uses a search-capability tool for the retrieval of information. In general, the agent will follow these steps when receiving a request:\n",
    "\n",
    "1. **Analyze the request.** The agent identifies the key elements of the query\n",
    "2. **Perform retrieval.** The agent leverages DuckDuckGo to search for the most relevant and up-to-date information\n",
    "3. **Synthesize information.** After gathering the results, the agent processes them iinto a single, cohesive response\n",
    "4. **Store for future reference.** The agent stores the retrieved information for easy access when planning future, similar requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchTool()\n",
    "\n",
    "model = HfApiModel()\n",
    "\n",
    "agent = CodeAgent(model = model,\n",
    "                  tools = [search_tool])\n",
    "agent.run(\"Search for luxury superhero-themed party ideas, including decorations, entertainment, and catering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Knowledge Base Tool\n",
    "\n",
    "In the case of more complex and specialized tasks, it's more useful to connect to a custom knowledge base where the agent can use **semantic search** to find the most relevant information based on the user request.\n",
    "\n",
    "The following example uses a tool that retrieves party planning ideas from a custom knowledge base using a *BM25 retriever* to search the knowledge base and return the top results, and *RecursiveCharacterTextSplitter* to split the documents into smaller chunks for a more efficient search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from smolagents import Tool\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from smolagents import CodeAgent, HfApiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartyPlanningRetrieverTool(Tool):\n",
    "    name = \"party_planning_retriever\"\n",
    "    description = \"Uses semantic search to retrieve relevant party planning ideas for Alfred’s superhero-themed party at Wayne Manor.\"\n",
    "    inputs = {\"query\": {\"type\": \"string\",\n",
    "                        \"description\": \"The query to perform. This should be a query related to party planning or superhero themes.\"}}\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(docs,\n",
    "                                                      k=5)  # Retrieve the top 5 documents\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(query)\n",
    "        return \"\\nRetrieved ideas:\\n\" + \"\".join([f\"\\n\\n===== Idea {str(i)} =====\\n\" + doc.page_content\n",
    "                                                 for i, doc in enumerate(docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a knowledge base about party planning\n",
    "party_ideas = [\n",
    "    {\"text\": \"A superhero-themed masquerade ball with luxury decor, including gold accents and velvet curtains.\", \"source\": \"Party Ideas 1\"},\n",
    "    {\"text\": \"Hire a professional DJ who can play themed music for superheroes like Batman and Wonder Woman.\", \"source\": \"Entertainment Ideas\"},\n",
    "    {\"text\": \"For catering, serve dishes named after superheroes, like 'The Hulk's Green Smoothie' and 'Iron Man's Power Steak.'\", \"source\": \"Catering Ideas\"},\n",
    "    {\"text\": \"Decorate with iconic superhero logos and projections of Gotham and other superhero cities around the venue.\", \"source\": \"Decoration Ideas\"},\n",
    "    {\"text\": \"Interactive experiences with VR where guests can engage in superhero simulations or compete in themed games.\", \"source\": \"Entertainment Ideas\"}\n",
    "]\n",
    "\n",
    "source_docs = [Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "               for doc in party_ideas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks for more efficient search\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500,\n",
    "                                               chunk_overlap = 50,\n",
    "                                               add_start_index = True,\n",
    "                                               strip_whitespace = True,\n",
    "                                               separators = [\"\\n\\n\", \"\\n\", \".\", \" \", \"\"])\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retriever tool\n",
    "party_planning_retriever = PartyPlanningRetrieverTool(docs_processed)\n",
    "\n",
    "# Initialize the agent\n",
    "agent = CodeAgent(tools=[party_planning_retriever], model=HfApiModel())\n",
    "agent.run(\"Find ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Systems\n",
    "\n",
    "There might be some use cases that are way too complex for a single agent to process due to all the data processing and reaction process it needs to follow.\n",
    "\n",
    "Multi-agent systems enable **specialized agents to collaborate on complex tasks**, improving modularity, scalability, and robustness. Instead of relying on a single agent, tasks are distributed among agents with distinct capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "# pip install 'smolagents[litellm]' matplotlib geopandas shapely kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will be to create a tool to get the cargo plane transfer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from smolagents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_cargo_travel_time(\n",
    "    origin_coords: Tuple[float, float],\n",
    "    destination_coords: Tuple[float, float],\n",
    "    cruising_speed_kmh: Optional[float] = 750.0) -> float:  # Average speed for cargo planes\n",
    "    \"\"\"Calculate the travel time for a cargo plane between two points on Earth using great-circle distance.\n",
    "\n",
    "    Args:\n",
    "        origin_coords: Tuple of (latitude, longitude) for the starting point\n",
    "        destination_coords: Tuple of (latitude, longitude) for the destination\n",
    "        cruising_speed_kmh: Optional cruising speed in km/h (defaults to 750 km/h for typical cargo planes)\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated travel time in hours\n",
    "\n",
    "    Example:\n",
    "        >>> # Chicago (41.8781° N, 87.6298° W) to Sydney (33.8688° S, 151.2093° E)\n",
    "        >>> result = calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093))\"\"\"\n",
    "\n",
    "    def to_radians(degrees: float) -> float:\n",
    "        return degrees * (math.pi / 180)\n",
    "\n",
    "    # Extract coordinates\n",
    "    lat1, lon1 = map(to_radians, origin_coords)\n",
    "    lat2, lon2 = map(to_radians, destination_coords)\n",
    "\n",
    "    # Earth's radius in kilometers\n",
    "    EARTH_RADIUS_KM = 6371.0\n",
    "\n",
    "    # Calculate great-circle distance using the haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = (math.sin(dlat / 2) ** 2\n",
    "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2)\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    distance = EARTH_RADIUS_KM * c\n",
    "\n",
    "    # Add 10% to account for non-direct routes and air traffic controls\n",
    "    actual_distance = distance * 1.1\n",
    "\n",
    "    # Calculate flight time\n",
    "    # Add 1 hour for takeoff and landing procedures\n",
    "    flight_time = (actual_distance / cruising_speed_kmh) + 1.0\n",
    "\n",
    "    # Format the results\n",
    "    return round(flight_time, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model provider will be **Together AI**, one of the new inference providers on HF Hub.\n",
    "\n",
    "The GoogleSearchTool can use either **Serper API** or **DuckDuckGo** to search the web. Just consider that the latter has a rate limit. You'll need an API key to use the Serper service though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, GoogleSearchTool, HfApiModel, VisitWebpageTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(model_id = \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "                   provider = \"together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128° N, 74.0060° W), and return them to me as a pandas dataframe.\n",
    "Also give me some supercar factories with the same cargo plane transfer time.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(model = model,\n",
    "                  tools = [DuckDuckGoSearchTool(), VisitWebpageTool(), calculate_cargo_travel_time], #GoogleSearchTool(\"serper\")\n",
    "                  additional_authorized_imports=[\"pandas\"],\n",
    "                  max_steps=20)\n",
    "agent.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use additional planning steps to allow the agent to think ahead and plan its next steps, improving the quality of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.planning_interval = 4\n",
    "\n",
    "detailed_report = agent.run(f\"\"\"You're an expert analyst. You make comprehensive reports after visiting many websites.\n",
    "Don't hesitate to search for many queries at once in a for loop.\n",
    "For each data point that you find, visit the source url to confirm numbers.\n",
    "\n",
    "{task}\"\"\")\n",
    "\n",
    "print(detailed_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the task between two agents\n",
    "\n",
    "Multi-agent structures allow to separate memories between different sub-tasks, with two great benefits:\n",
    "\n",
    "* Each agent is more focused on its core task, thus more performant\n",
    "* Separating memories reduces the count of input tokens at each step, thus reducing latency and cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *web agent* will have plotting capabilities to write its final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "                   provider = \"together\",\n",
    "                   max_tokens = 8096)\n",
    "\n",
    "web_agent = CodeAgent(model = model,\n",
    "                      tools = [DuckDuckGoSearchTool(), #GoogleSearchTool(provider=\"serper\"),\n",
    "                               VisitWebpageTool(),\n",
    "                               calculate_cargo_travel_time],\n",
    "                      name = \"web_agent\",\n",
    "                      description = \"Browses the web to find information\",\n",
    "                      verbosity_level = 0,\n",
    "                      max_steps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *manager agent* will be in charge of planning the necessary intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents.utils import encode_image_base64, make_image_url\n",
    "from smolagents import OpenAIServerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reasoning_and_plot(final_answer, agent_memory):\n",
    "    multimodal_model = OpenAIServerModel(\"gpt-4o\", max_tokens = 8096)\n",
    "    filepath = \"saved_map.png\"\n",
    "    assert os.path.exists(filepath), \"Make sure to save the plot under saved_map.png!\"\n",
    "    image = Image.open(filepath)\n",
    "    \n",
    "    prompt = (f\"Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the plot that was made.\"\n",
    "        \"Please check that the reasoning process and plot are correct: do they correctly answer the given task?\"\n",
    "        \"First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\"\n",
    "        \"Don't be harsh: if the plot mostly solves the task, it should pass.\"\n",
    "        \"To pass, a plot should be made using px.scatter_map and not any other method (scatter_map looks nicer).\")\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": make_image_url(encode_image_base64(image))},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    output = multimodal_model(messages).content\n",
    "    print(\"Feedback: \", output)\n",
    "    if \"FAIL\" in output:\n",
    "        raise Exception(output)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent = CodeAgent(model = HfApiModel(\"deepseek-ai/DeepSeek-R1\",\n",
    "                                             provider = \"together\",\n",
    "                                             max_tokens = 8096),\n",
    "                          tools = [calculate_cargo_travel_time],\n",
    "                          managed_agents = [web_agent],\n",
    "                          additional_authorized_imports = [\"geopandas\", \"plotly\", \"shapely\", \"json\", \"pandas\", \"numpy\"],\n",
    "                          planning_interval = 5,\n",
    "                          verbosity_level = 2,\n",
    "                          final_answer_checks = [check_reasoning_and_plot],\n",
    "                          max_steps = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent.run(\"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128° N, 74.0060° W).\n",
    "Also give me some supercar factories with the same cargo plane transfer time. You need at least 6 points in total.\n",
    "Represent this as spatial map of the world, with the locations represented as scatter points with a color that depends on the travel time, and save it to saved_map.png!\n",
    "\n",
    "Here's an example of how to plot and return a map:\n",
    "import plotly.express as px\n",
    "df = px.data.carshare()\n",
    "fig = px.scatter_map(df, lat=\"centroid_lat\", lon=\"centroid_lon\", text=\"name\", color=\"peak_hour\", size=100,\n",
    "     color_continuous_scale=px.colors.sequential.Magma, size_max=15, zoom=1)\n",
    "fig.show()\n",
    "fig.write_image(\"saved_image.png\")\n",
    "final_answer(fig)\n",
    "\n",
    "Never try to process strings using code: when you have a string to read, just print it and you'll see it.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Agents\n",
    "\n",
    "It has been more common to find use cases that go beyond text processing. For this reason, it's important to provide agents with visual capabilities as well through the use of **Vision-Language Models (VSM)**.\n",
    "\n",
    "The following samples will use an agent that verifies the identity of people by searching for visual information about their appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing Images at the Start of the Agent's Execution\n",
    "\n",
    "This approach passes images to the agent **at the start and stores them as *task_images*** alongside the task prompt. The agent then processes the images throughout its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from smolagents import CodeAgent, OpenAIServerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = [\"https://upload.wikimedia.org/wikipedia/commons/e/e8/The_Joker_at_Wax_Museum_Plus.jpg\", # Joker image\n",
    "              \"https://upload.wikimedia.org/wikipedia/en/9/98/Joker_%28DC_Comics_character%29.jpg\"] # Joker image\n",
    "\n",
    "images = []\n",
    "for url in image_urls:\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIServerModel(model_id = \"gpt-4o\")\n",
    "\n",
    "# Instantiate the agent\n",
    "agent = CodeAgent(tools = [],\n",
    "                  model = model,\n",
    "                  max_steps = 20,\n",
    "                  verbosity_level = 2)\n",
    "\n",
    "response = agent.run(\"\"\"Describe the costume and makeup that the comic character in these photos is wearing and return the description.\n",
    "                     Tell me if the guest is The Joker or Wonder Woman.\"\"\",\n",
    "                     images = images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing Images with Dynamic Retrieval\n",
    "\n",
    "Another implementation can be thorugh **retrieving dynamically images and information from external sources**. In this case, images are added to the agent's memory during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "# pip install \"smolagents[all]\" helium selenium python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_item_ctrl_f(text: str, nth_result: int = 1) -> str:\n",
    "    \"\"\"Searches for text on the current page via Ctrl + F and jumps to the nth occurrence.\n",
    "    Args:\n",
    "        text: The text to search for\n",
    "        nth_result: Which occurrence to jump to (default: 1)\"\"\"\n",
    "    \n",
    "    elements = driver.find_elements(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
    "\n",
    "    if nth_result > len(elements):\n",
    "        raise Exception(f\"Match n°{nth_result} not found (only {len(elements)} matches found)\")\n",
    "    \n",
    "    result = f\"Found {len(elements)} matches for '{text}'.\"\n",
    "    elem = elements[nth_result - 1]\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
    "    result += f\"Focused on element {nth_result} of {len(elements)}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def go_back() -> None:\n",
    "    \"\"\"Goes back to previous page.\"\"\"\n",
    "    \n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def close_popups() -> str:\n",
    "    \"\"\"Closes any visible modal or pop-up on the page. Use this to dismiss pop-up windows! This does not work on cookie consent banners.\"\"\"\n",
    "    \n",
    "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
